{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from f1optimization_faron import get_best_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function returns the predicted product recommendations if its existing user, else returns \n",
    "    most frequently purchased product at that hour and on that day.\n",
    "    \n",
    "    user_id           : provided\n",
    "    order_hour_of_day : calculated by seeing current time\n",
    "    order_dow         : calulated by seeing current day of week\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #get current time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    today = int(dt_string.split(\"/\")[0])\n",
    "\n",
    "    #get data from user end\n",
    "    user_id = int(X['user_id']) #user_id\n",
    "    order_hour_of_day = int(dt_string.split(\" \")[1].split(\":\")[0]) #current date\n",
    "    order_dow = datetime.today().weekday() #current day of week\n",
    "\n",
    "    \"\"\"\n",
    "    check if the user is new or existing,\n",
    "    this file contains user's last order date\n",
    "    \n",
    "    Handling: since in our model days since prior order is a feature, which cannot be calculated without user's last order date.\n",
    "              assuming that this model is deployed on 21-march-2021, all users last order are taken as 21-march-2021.\n",
    "              But this assumption likely introduces new bugs.\n",
    "              Ex- user A , never made a purchase with days_prior_order = 3, if he makes he does this in future , the below handles,\n",
    "              such exceptions\n",
    "    \"\"\"\n",
    "    \n",
    "    ulp = pd.read_pickle(\"user_last_purchase.pkl\")\n",
    "    \n",
    "    #if user is new -> cold start -> recommend products which are most frequently purchased based on time and day of week\n",
    "    if user_id not in ulp['user_id'].values:\n",
    "\n",
    "        #get top 10 products based on hour of day and day of week\n",
    "        top= pd.read_pickle('top10_products.pkl')\n",
    "        top_products = top[(top['order_dow']==order_dow) & (top['order_hour_of_day']==order_hour_of_day)]['product_name'].values.tolist()\n",
    "        top_products = {i: value for i,value in enumerate(top_products)}\n",
    "        #paths = get_image_paths(top5_products)\n",
    "        predictions={}\n",
    "        predictions['top'] =  top_products\n",
    "\n",
    "        del ulp, top,now, today, dt_string, order_dow, order_hour_of_day\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        difference = end_time - start_time\n",
    "        #print(\"Total Time : {} seconds\".format(difference))\n",
    "        time = \"{}\".format(difference)\n",
    "        \n",
    "        return predictions,time\n",
    "    \n",
    "    #if user is existing one\n",
    "    user_last_order_date = ulp[ulp['user_id']==user_id]['date'].values.tolist()[0]\n",
    "\n",
    "    days_since_prior_order = today - int(user_last_order_date.split('-')[-1])\n",
    "    del ulp, now, today, dt_string, user_last_order_date\n",
    "    \n",
    "    #build features\n",
    "    hour_rate = pd.read_csv(\"hour_reorder_rate.csv\")\n",
    "    day_rate = pd.read_csv(\"day_reorder_rate.csv\")\n",
    "    p_days_rate = pd.read_csv(\"p_days_since_prior_order_reorder_rate.csv\")\n",
    "    u_days_rate = pd.read_csv(\"u_days_since_prior_order_reorder_rate.csv\")\n",
    "    up_days_rate = pd.read_csv(\"days_since_prior_reorder_rate.csv\")\n",
    "    merged_up_features = pd.read_csv(\"merged_user_product_features.csv\")\n",
    "\n",
    "    #collect features based on hour of day , day of week, and user id\n",
    "    featurized_data = merged_up_features[merged_up_features['user_id']==user_id]\n",
    "    hour_r = hour_rate[hour_rate['order_hour_of_day']==order_hour_of_day]\n",
    "    day_r = day_rate[day_rate['order_dow'] == order_dow]\n",
    "    p_days = p_days_rate[p_days_rate['days_since_prior_order']==days_since_prior_order]\n",
    "    u_days = u_days_rate[(u_days_rate['user_id']==user_id) & (u_days_rate['days_since_prior_order']==days_since_prior_order)]\n",
    "    \n",
    "    \"\"\"\n",
    "    if user never made a purchase in the gap of (days_since_prior_order) between 2 orders, make a new dataframe, \n",
    "    with the given number of days , and with reorder_rate = 0.0\n",
    "    \"\"\"\n",
    "    \n",
    "    if p_days.empty:\n",
    "        #handle\n",
    "        p_days = pd.DataFrame(columns = p_days.columns)\n",
    "        products_x = pd.read_pickle('product_mappings.pkl')\n",
    "        p_days['product_id'] = products_x['product_id']\n",
    "        p_days['days_since_prior_order'] = days_since_prior_order\n",
    "        p_days['p_days_since_prior_order_reorder_rate']=0.0\n",
    "    \n",
    "    up_days = up_days_rate[(up_days_rate['user_id']==user_id) & (up_days_rate['days_since_prior_order']==days_since_prior_order)]\n",
    "\n",
    "    if up_days.empty:\n",
    "        #handle\n",
    "        up_days = pd.DataFrame(columns = up_days_rate.columns)\n",
    "        products_x = pd.read_pickle('product_mappings.pkl')\n",
    "        up_days['product_id'] = products_x['product_id']\n",
    "        up_days['user_id'] = user_id\n",
    "        up_days['days_since_prior_order'] = days_since_prior_order\n",
    "        up_days['days_since_prior_reorder_rate']=0\n",
    "        del products_x\n",
    "    \n",
    "    if u_days.empty:\n",
    "        #handle\n",
    "        u_days = pd.DataFrame(columns = u_days.columns)\n",
    "        df2 = {'user_id': user_id, 'days_since_prior_order': days_since_prior_order, 'u_days_since_prior_order_reorder_rate': 0}\n",
    "        u_days = u_days.append(df2, ignore_index = True)\n",
    "        del df2\n",
    "\n",
    "    up_days = up_days_rate[(up_days_rate['user_id']==user_id) & (up_days_rate['days_since_prior_order']==days_since_prior_order)]\n",
    "    \n",
    "    \"\"\"\n",
    "    if user never made a purchase in the gap of (days_since_prior_order) between 2 orders, make a new dataframe, \n",
    "    with the given number of days , and with reorder_rate = 0.0\n",
    "    \"\"\"\n",
    "    if up_days.empty:\n",
    "        #handle\n",
    "        up_days = pd.DataFrame(columns = up_days_rate.columns)\n",
    "        products_x = pd.read_pickle('product_mappings.pkl')\n",
    "        up_days['product_id'] = products_x['product_id']\n",
    "        up_days['user_id'] = user_id\n",
    "        up_days['days_since_prior_order'] = days_since_prior_order\n",
    "        up_days['days_since_prior_reorder_rate']=0\n",
    "        del products_x\n",
    "\n",
    "\n",
    "    #print(up_days_rate[up_days_rate['user_id']==user_id])\n",
    "    #print(u_days_rate[u_days_rate['user_id']==user_id])\n",
    "    #print(day_rate)\n",
    "    del merged_up_features, hour_rate, day_rate, p_days_rate, u_days_rate, up_days_rate\n",
    "\n",
    "    featurized_data = pd.merge(featurized_data, up_days, on = ['user_id', 'product_id'])\n",
    "\n",
    "    featurized_data = pd.merge(featurized_data, hour_r, on = 'product_id')\n",
    "    featurized_data = pd.merge(featurized_data, day_r, on = 'product_id')\n",
    "    featurized_data = pd.merge(featurized_data, p_days, on = ['product_id','days_since_prior_order'])\n",
    "    featurized_data = pd.merge(featurized_data, u_days, on = ['user_id','days_since_prior_order'])\n",
    "    featurized_data = featurized_data[['user_id', 'product_id', 'u_p_order_rate', 'u_p_reorder_rate',\\\n",
    "                                       'u_p_avg_position', 'u_p_orders_since_last', 'max_streak', 'user_reorder_rate',\\\n",
    "                                       'user_unique_products', 'user_total_products', 'user_avg_cart_size', \\\n",
    "                                       'user_avg_days_between_orders', 'user_reordered_products_ratio', \\\n",
    "                                       'product_reorder_rate', 'avg_pos_incart', 'p_reduced_feat_1', 'p_reduced_feat_2', \\\n",
    "                                       'p_reduced_feat_3', 'aisle_id', 'department_id', 'aisle_reorder_rate', \\\n",
    "                                       'dept_reorder_rate', 'order_dow', 'order_hour_of_day', 'days_since_prior_order',\\\n",
    "                                       'hour_reorder_rate', 'day_reorder_rate', 'p_days_since_prior_order_reorder_rate',\\\n",
    "                                       'u_days_since_prior_order_reorder_rate', 'days_since_prior_reorder_rate']]\n",
    "\n",
    "    del up_days,u_days,p_days,day_r,hour_r\n",
    "\n",
    "    #model\n",
    "    model=tf.keras.models.load_model('saved_model/mlp/checkpoint.hdf5')\n",
    "    #model = pickle.load(open(\"catboost_v3.pkl\", \"rb\"))\n",
    "    \n",
    "    data = featurized_data.drop(['user_id', 'product_id'], axis = 1)\n",
    "    data.fillna(value=0, inplace=True)\n",
    "    # data=np.array(data).astype(np.int64)\n",
    "\n",
    "    data['u_p_order_rate'] = data['u_p_order_rate'].astype('float16')\n",
    "    data['u_p_reorder_rate'] = data['u_p_reorder_rate'].astype('float16')\n",
    "    data['u_p_avg_position'] = data['u_p_avg_position'].astype('float16')\n",
    "    data['u_p_orders_since_last'] = data['u_p_orders_since_last'].astype('int8')\n",
    "    data['max_streak'] = data['max_streak'].astype('int8')\n",
    "    data['user_reorder_rate'] = data['user_reorder_rate'].astype('float16')\n",
    "    data['user_unique_products'] = data['user_unique_products'].astype('int16')\n",
    "    data['user_total_products'] = data['user_total_products'].astype('int16')\n",
    "    data['user_avg_cart_size'] = data['user_avg_cart_size'].astype('float16')\n",
    "    data['user_avg_days_between_orders'] = data['user_avg_days_between_orders'].astype('float16')\n",
    "    data['user_reordered_products_ratio'] = data['user_reordered_products_ratio'].astype('float16')\n",
    "    data['product_reorder_rate'] = data['product_reorder_rate'].astype('float16')\n",
    "    data['avg_pos_incart'] = data['avg_pos_incart'].astype('float16')\n",
    "    data['p_reduced_feat_1'] = data['p_reduced_feat_1'].astype('float16')\n",
    "    data['p_reduced_feat_2'] = data['p_reduced_feat_2'].astype('float16')\n",
    "    data['p_reduced_feat_3'] = data['p_reduced_feat_3'].astype('float16')\n",
    "    data['aisle_id'] = data['aisle_id'].astype('uint8')\n",
    "    data['department_id'] = data['department_id'].astype('uint8')\n",
    "    data['aisle_reorder_rate'] = data['aisle_reorder_rate'].astype('float16')\n",
    "    data['dept_reorder_rate'] = data['dept_reorder_rate'].astype('float16')\n",
    "    data['order_dow'] = data['order_dow'].astype('uint8')\n",
    "    data['order_hour_of_day'] = data['order_hour_of_day'].astype('uint8')\n",
    "    data['days_since_prior_order'] = data['days_since_prior_order'].astype('uint8')\n",
    "    data['hour_reorder_rate'] = data['hour_reorder_rate'].astype('float32')\n",
    "    data['day_reorder_rate'] = data['day_reorder_rate'].astype('float32')\n",
    "    data['p_days_since_prior_order_reorder_rate'] = data['p_days_since_prior_order_reorder_rate'].astype('float32')\n",
    "    data['u_days_since_prior_order_reorder_rate'] = data['u_days_since_prior_order_reorder_rate'].astype('float32')\n",
    "    data['days_since_prior_reorder_rate'] = data['days_since_prior_reorder_rate'].astype('float32')\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # fit scaler on training data\n",
    "    scaler = StandardScaler().fit(data)\n",
    "\n",
    "    # transforming the data\n",
    "    data = scaler.transform(data)\n",
    "    # data=np.asarray(data)\n",
    "    print(data.shape)\n",
    "    print(data)\n",
    "\n",
    "    ypred = model.predict(data)\n",
    "    ypred = ypred[:,-1] #get probabilities of class 1\n",
    "    del data, model\n",
    "\n",
    "    #run faron's optimization code to get most probable set of products which might be reordered\n",
    "    \n",
    "    #set showThreshold = True , while debugging to print the threshold\n",
    "    recommended_products = get_best_prediction(featurized_data['product_id'].tolist(), ypred.tolist(), None, showThreshold = True)\n",
    "    recommended_products = recommended_products.replace(\"None\", \"\")\n",
    "    recommended_products = list(map(int, recommended_products.split()))\n",
    "    products_x = pd.read_pickle('product_mappings.pkl')\n",
    "    recommended_products = products_x.loc[products_x['product_id'].isin(recommended_products)]['product_name'].values.tolist()\n",
    "    recommended_products = {i: value for i,value in enumerate(recommended_products)}\n",
    "\n",
    "    predictions= {}\n",
    "    predictions['recommend'] = recommended_products\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    difference = end_time - start_time\n",
    "    #print(\"Total Time : {} seconds\".format(difference))\n",
    "    time = \"{}\".format(difference)\n",
    "\n",
    "    del featurized_data, products_x\n",
    "    return predictions, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 28)\n",
      "[[ 0.05472781  0.8121386   0.47234112 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.5883239  -0.70120376  0.8949787  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.5883239  -0.70120376  0.3314619  ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.05472781  0.8121386  -1.2182095  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.5883239  -0.70120376  2.5855293  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.5883239  -0.70120376  0.6132203  ...  0.          0.\n",
      "   0.        ]]\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "\n",
      "=========================\n",
      "Recommended products\n",
      "=========================\n",
      "Organic Turkey Bone Broth\n",
      "Nutritional Yeast Seasoning\n",
      "French Vanilla Coconut Milk Creamer\n",
      "Carrots\n",
      "My Community Immune Support Dietary Supplement\n",
      "Organic Egg Whites\n",
      "Broccoli Slaw Traditional\n",
      "Coconut Butter\n"
     ]
    }
   ],
   "source": [
    "#existing user\n",
    "\n",
    "X = {}\n",
    "X['user_id'] = 202279\n",
    "recommended_products = prediction(X)\n",
    "\n",
    "print()\n",
    "print(\"=\"*25)\n",
    "print(\"Recommended products\")\n",
    "print(\"=\"*25)\n",
    "for _,value in recommended_products[0]['recommend'].items():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 28)\n",
      "[[-0.6745404  -0.86451566 -0.01257048 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.6438596   1.1423957  -0.78855574 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.6745404  -0.86451566  0.70393896 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.6438596   1.1423957  -0.07274608 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.6745404  -0.86451566  1.7787031  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.6745404  -0.86451566 -0.37082517 ...  0.          0.\n",
      "   0.        ]]\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "\n",
      "=========================\n",
      "Recommended products\n",
      "=========================\n",
      "Imported Mineral Water\n",
      "Organic Bunny Fruit Snacks Berry Patch\n",
      "Chocolate Peppermint Stick Bar\n",
      "Organic Sticks Low Moisture Part Skim Mozzarella String Cheese\n",
      "Organic Summer Strawberry Bunny Fruit Snacks\n",
      "Goldfish Cheddar Baked Snack Crackers\n",
      "Organics Chocolate Milk with DHA\n",
      "Original Whipped Cream Cheese\n",
      "Organic Uncured Sliced Black Forest Ham\n",
      "Pirate's Booty Aged White Cheddar Baked Rice and Corn Puffs\n",
      "Plain Mini Bagels\n",
      "Grape White/Green Seedless\n"
     ]
    }
   ],
   "source": [
    "#existing user\n",
    "\n",
    "X = {}\n",
    "X['user_id'] = 55\n",
    "recommended_products = prediction(X)\n",
    "\n",
    "print()\n",
    "print(\"=\"*25)\n",
    "print(\"Recommended products\")\n",
    "print(\"=\"*25)\n",
    "for _,value in recommended_products[0]['recommend'].items():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Recommended products\n",
      "=========================\n",
      "Banana\n",
      "Bag of Organic Bananas\n",
      "Organic Baby Spinach\n",
      "Organic Strawberries\n",
      "Organic Hass Avocado\n",
      "Organic Avocado\n",
      "Large Lemon\n",
      "Limes\n",
      "Organic Yellow Onion\n",
      "Strawberries\n",
      "Time taken : 0:00:00.048000\n"
     ]
    }
   ],
   "source": [
    "#new user\n",
    "\n",
    "X = {}\n",
    "X['user_id'] = 225000\n",
    "recommended_products = prediction(X)\n",
    "print(\"=\"*25)\n",
    "print(\"Recommended products\")\n",
    "print(\"=\"*25)\n",
    "for _,value in recommended_products[0]['top'].items():\n",
    "    print(value)\n",
    "print(\"Time taken :\", recommended_products[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
